{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c8d1b3",
   "metadata": {},
   "source": [
    "## Semantization of simulated data step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fcdc45",
   "metadata": {},
   "source": [
    "This notebook will go through the different stages of building a Turtle file that follows the SPHN framework using simulated patient data in `JSON` format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47814302",
   "metadata": {},
   "source": [
    "### Import libraries and start a graph file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "15768ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import URIRef, Graph, Namespace, Literal\n",
    "from rdflib.namespace import RDF, OWL, XSD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddbfa72",
   "metadata": {},
   "source": [
    "Note that we imported `namespaces` which will be used as prefixes for the generation of our semantized data. Since we need to follow the SPHN framework, we will also create create SPHN prefixes using `Namespace`. To do that, we first need to import the SPHN ontology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f0b0f8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8693\n",
      "8693\n",
      "8694\n"
     ]
    }
   ],
   "source": [
    "g = Graph()\n",
    "\n",
    "# Importing ontology\n",
    "g.parse(\"sphn_ontology.ttl\")\n",
    "print(len(g))\n",
    "\n",
    "# Adding allergies and patients as prefixes\n",
    "allergies = Namespace(\"http://sib.swiss/allergies/\")\n",
    "g.bind(\"allergies\", allergies)\n",
    "patients = Namespace(\"http://sib.swiss/fictivePatients/\")\n",
    "g.bind(\"patients\", patients)\n",
    "\n",
    "# Adding also SPHN as a variable since this is not automatic\n",
    "sphn = Namespace(\"https://biomedit.ch/rdf/sphn-ontology/sphn#\")\n",
    "\n",
    "# Note that adding namespaces doesn't change the length of the file\n",
    "# because we still didn't use those namespaces\n",
    "print(len(g))\n",
    "\n",
    "# We can test that by adding an ID\n",
    "ID_test = \"6824c567-a5b2-8741-2dc4-b13ec092dd27\"\n",
    "\n",
    "g.add((URIRef(patients + ID_test), RDF.type, sphn.SubjectPseudoIdentifier))\n",
    "print(len(g))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08722c1",
   "metadata": {},
   "source": [
    "### Import JSON file and find the variables of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901f4983",
   "metadata": {},
   "source": [
    "Now that we're ready to add elements to the graph, we can import some test patient data in `JSON` format and look for their patient ID and allergies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ed49dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6824c567-a5b2-8741-2dc4-b13ec092dd27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24    [environment]\n",
       "Name: resource.category, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load data\n",
    "data = json.load(open('test_patient.json', 'r'))\n",
    "\n",
    "# Navigating through the JSON is not easy but looking at the file structure helps\n",
    "\n",
    "# Patient ID location\n",
    "print(data['entry'][0]['resource']['id'])\n",
    "\n",
    "# for the allergy location, it becomes more convenient to convert \n",
    "# data into a dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(pd.json_normalize(data['entry']), orient='columns')\n",
    "\n",
    "# Check column where allergies could be\n",
    "\n",
    "pd.unique(df['resource.resourceType'])\n",
    "\n",
    "# We isolate the rows with allergies and get the allergy name(s)\n",
    "\n",
    "allergies_rows = df[df['resource.resourceType'] == 'AllergyIntolerance']\n",
    "allergen = allergies_rows['resource.code.text']\n",
    "allergen\n",
    "\n",
    "# We isolate the allergy type as well\n",
    "\n",
    "allergies_types = allergies_rows['resource.category']\n",
    "allergies_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97008450-75c7-4ec0-ae95-c80adb76495b",
   "metadata": {},
   "source": [
    "### Create loops to add elements of interest to graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc01438-1bc0-4427-ad26-492f9b32d53e",
   "metadata": {},
   "source": [
    "Now we will create a for loop that will take the allergies, link them to their type and link them to the initial patient ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8331897b-fcee-4fd1-a15d-35abe5154a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We repeat the code from above to recontruct our ontology from scratch\n",
    "\n",
    "# Importing ontology\n",
    "g = Graph()\n",
    "g.parse(\"sphn_ontology.ttl\")\n",
    "\n",
    "# Adding allergies and patients as prefixes\n",
    "allergies = Namespace(\"http://sib.swiss/allergies/\")\n",
    "g.bind(\"allergies\", allergies)\n",
    "patients = Namespace(\"http://sib.swiss/fictivePatients/\")\n",
    "g.bind(\"patients\", patients)\n",
    "substances = Namespace(\"http://sib.swiss/substances/\")\n",
    "g.bind(\"substances\", substances)\n",
    "\n",
    "# Adding also SPHN as a variable since this is not automatic\n",
    "sphn = Namespace(\"https://biomedit.ch/rdf/sphn-ontology/sphn#\")\n",
    "\n",
    "# Adding patient ID to the ontology\n",
    "ID_test = Literal(data['entry'][0]['resource']['id'])\n",
    "g.add((patients.ID_test, RDF.type, sphn.SubjectPseudoIdentifier))\n",
    "\n",
    "# We create a list of allergy types to not create redundant nodes\n",
    "allergy_types_all = []\n",
    "\n",
    "# And we do the same for allergy substances\n",
    "allergy_substances = []\n",
    "\n",
    "# We create a splitting function to extract the terms we need\n",
    "# from the allergies found above\n",
    "\n",
    "def split_allergen(allergen):\n",
    "    first_split = Literal(allergen).split(' (')[0]\n",
    "    return(first_split)\n",
    "\n",
    "def split_allergies_types(allergies):\n",
    "    first_split = Literal(allergies).split('[')[1]\n",
    "    second_split = first_split.split(']')[0]\n",
    "    return(second_split)\n",
    "\n",
    "# Both the functions above return a clean literal\n",
    "\n",
    "# Now we create a loop to go through the terms\n",
    "# and add them to our ontology\n",
    "\n",
    "for i,j in zip(allergen,allergies_types):\n",
    "    # Convert allergy type and substance to literal\n",
    "    allergy_type = Literal(split_allergies_types(j))\n",
    "    allergy_substance = Literal(split_allergen(i))\n",
    "    \n",
    "    # Check if any is part of a global list\n",
    "    # and if not, we can add them to the ontology\n",
    "    \n",
    "    if allergy_type not in allergy_types_all:\n",
    "        allergy_types_all.append(allergy_type)\n",
    "        g.add((URIRef(allergies + allergy_type), RDF.type, sphn.Allergy))\n",
    "        \n",
    "    if allergy_substance not in allergy_substances:\n",
    "        allergy_substances.append(allergy_substance)\n",
    "        g.add((URIRef(allergies + allergy_type), sphn.hasSubstance, URIRef(substances + allergy_substance)))\n",
    "    \n",
    "    # Add to ontology by associating to the patient ID\n",
    "    g.add((URIRef(allergies + allergy_type), sphn.SubjectPseudoIdentifier, URIRef(patients + ID_test)))\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0b514b61-a65e-4420-908c-df0bbf2fd7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rdflib.term.Literal(\"'food'\")]\n",
      "[rdflib.term.Literal('Peanut')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8697"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check if our global lists have been filled and if our ontology has additional elements\n",
    "\n",
    "print(allergy_types_all)\n",
    "print(allergy_substances)\n",
    "\n",
    "# ontology size\n",
    "len(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a13ba76-f85c-4605-936c-b73ccb8df206",
   "metadata": {},
   "source": [
    "With all of this information, we will now create a script that will:\n",
    "\n",
    " - Loop through each `JSON` file\n",
    " - Get patient ID, allergies substances and types\n",
    " - Add all of these iteratively to our ontology linking them to the patient\n",
    " - If an allergy type and/or substance is not in a global list, add their relationship\n",
    " - As a last step write a new Turtle file with the new ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335da49-0fd2-4915-bb11-c9b03bb51cc2",
   "metadata": {},
   "source": [
    "### Final loop skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af35651-2fe1-4ebf-a8b9-0a704e02e579",
   "metadata": {},
   "source": [
    "First we want to loop through all the patient files we generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a59783be-ff05-4e1e-a15f-bee976a55c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../01_simulation/Jerilyn993_Ngoc221_Wyman904_9070913e-8d33-3568-750f-e330b1fbddb1.json\n",
      "No allergies found!\n",
      "../01_simulation/Cordell41_Balistreri607_4cd812cc-e2ec-f5d7-585f-a2b64e9caad8.json\n",
      "No allergies found!\n",
      "../01_simulation/Katrina8_McGlynn426_9bb595e8-e91c-8a40-1919-a3a01800d780.json\n",
      "No allergies found!\n",
      "../01_simulation/Irene779_Berneice173_Mann644_d1f1d721-e00c-a3f7-1d2b-a06a951f6bad.json\n",
      "No allergies found!\n",
      "../01_simulation/Ella812_Lai148_Brakus656_2757674c-248e-5ed9-c44e-f8f805b12598.json\n",
      "No allergies found!\n",
      "../01_simulation/Arlen68_Barrows492_88f98dbb-0906-40b0-36cc-870eeaf455d6.json\n",
      "No allergies found!\n",
      "../01_simulation/Justin359_Dickinson688_c3fa6f65-9f26-df9c-5908-85fbfd2c3d21.json\n",
      "No allergies found!\n",
      "../01_simulation/Leonard963_Moen819_82e4ffca-e402-5773-ea88-d52a2f1a970e.json\n",
      "No allergies found!\n",
      "../01_simulation/Warren653_Maggio310_cb927656-00cc-e6b6-8caf-fd38b1959e65.json\n",
      "No allergies found!\n",
      "../01_simulation/Benjamin360_Rice937_5c60f4ee-dc7f-522a-e9a6-968b6af1853e.json\n",
      "No allergies found!\n",
      "../01_simulation/Candis134_Schuster709_6a653a44-4468-dc46-2826-cd6a6c089ea1.json\n",
      "No allergies found!\n",
      "../01_simulation/Evalyn273_Botsford977_a4f097ad-9184-b194-3a30-1afac545b94f.json\n",
      "No allergies found!\n",
      "../01_simulation/Daron260_Lockman863_9ecc1322-3b82-ed40-4a24-cbc0ad16c904.json\n",
      "No allergies found!\n",
      "../01_simulation/Karl184_Hayes766_b8552968-7e78-22fa-6d84-0e943aad8747.json\n",
      "No allergies found!\n",
      "../01_simulation/Vita624_Tess185_Bernier607_5ab46f26-5979-ddc9-722f-e97f0d6aae1c.json\n",
      "Allergies found!\n",
      "../01_simulation/Carrol931_Miller503_73a41f64-6d15-1d65-11de-d01fc797a379.json\n",
      "No allergies found!\n",
      "../01_simulation/Filomena215_Gislason620_3c2778d9-4f1d-06e7-86f1-a94c442d40e2.json\n",
      "Allergies found!\n",
      "../01_simulation/Teodoro374_Labadie908_b9379856-f342-ad06-9bb7-d196bad0a78e.json\n",
      "Allergies found!\n",
      "../01_simulation/Ernesto186_Gonzales379_615f8529-8511-fa5b-087c-143422dfdc46.json\n",
      "No allergies found!\n",
      "../01_simulation/Kermit56_Stroman228_9ba047eb-32c1-6b7e-52a1-8b504a7ca41f.json\n",
      "No allergies found!\n",
      "../01_simulation/Jamie386_O'Kon634_f2f5a466-c1e3-96d2-3a6f-b5f8904d37f3.json\n",
      "No allergies found!\n",
      "../01_simulation/Clair921_Tarsha65_Harber290_6402d161-8d2e-fb18-9ffa-209e93788e4b.json\n",
      "Allergies found!\n",
      "../01_simulation/Ardella559_Bayer639_e095c3b0-90ee-7fdd-9697-69e5faf821e3.json\n",
      "No allergies found!\n",
      "../01_simulation/Eldridge510_Dare640_0a68c365-8355-a093-1ba4-c509fce8b9bf.json\n",
      "No allergies found!\n",
      "../01_simulation/Simon598_Mohr916_980cf8de-9e23-5474-28b8-7236c65577a0.json\n",
      "No allergies found!\n",
      "../01_simulation/Isidra572_Leah288_Treutel973_c85d8800-022c-d8da-942d-5956b2a8e2e6.json\n",
      "No allergies found!\n",
      "../01_simulation/Dana512_Funk324_65d8dae4-a3bf-fa09-fedd-8df67cd4df8e.json\n",
      "No allergies found!\n",
      "../01_simulation/Esperanza675_Lurlene215_Heaney114_80613e96-4ba1-eb00-5a45-0438622bd984.json\n",
      "Allergies found!\n",
      "../01_simulation/Venus149_Janel230_Gutkowski940_b0aa43fb-57c4-1b8e-8d0d-8ff292401cc3.json\n",
      "No allergies found!\n",
      "../01_simulation/Mohamed943_Runolfsdottir785_cfd384db-112e-a234-ae28-ef968c786720.json\n",
      "No allergies found!\n",
      "../01_simulation/Sebrina910_Kelsie51_Rowe323_3c2a0b00-8c39-47ec-2fb3-36f110de0b12.json\n",
      "No allergies found!\n",
      "../01_simulation/Harvey63_Quitzon246_1c3c4386-f6d9-2709-16c0-cd02d8488476.json\n",
      "No allergies found!\n",
      "../01_simulation/Palmer257_Collins926_56791478-5ff9-09d9-6716-40db3fbcf77f.json\n",
      "No allergies found!\n",
      "../01_simulation/Sigrid676_Myung778_Hauck852_0f9f0e44-ae0e-31f6-d075-db5db10b6dac.json\n",
      "No allergies found!\n",
      "../01_simulation/Shela13_Nolan344_1d786bb6-1e28-1fa1-a58f-f6257f57ffa0.json\n",
      "Allergies found!\n",
      "../01_simulation/Shad704_Eichmann909_34e854d0-dadd-5310-aa88-2b4d2ac13537.json\n",
      "No allergies found!\n",
      "../01_simulation/Shasta644_Jacobi462_fe5b74b1-11d5-d371-a38c-15cb4094ef36.json\n",
      "No allergies found!\n",
      "../01_simulation/Erwin847_Wehner319_9ceb906f-71b4-50e7-7c3a-c60f28824158.json\n",
      "No allergies found!\n",
      "../01_simulation/Esta787_Carrol931_Donnelly343_597f52c9-b7dd-8db4-19e9-c4b0a7738764.json\n",
      "No allergies found!\n",
      "../01_simulation/Jacob959_Bogan287_22c11b97-3438-f87c-a75a-6fab5502815a.json\n",
      "No allergies found!\n",
      "../01_simulation/Domingo513_Greenfelder433_6432fb62-79a7-e2d5-a2dd-8cd616cac374.json\n",
      "No allergies found!\n",
      "../01_simulation/Rick943_Gutkowski940_a5a62e95-acf7-895b-92b2-0384195adba9.json\n",
      "No allergies found!\n",
      "../01_simulation/Candra395_Ryan260_3ca026fd-617a-e600-0974-675e898bcd7f.json\n",
      "No allergies found!\n",
      "../01_simulation/Flavia315_Camelia346_Reichel38_1e59d47b-30d3-958f-9b82-a2ae0e7516b2.json\n",
      "No allergies found!\n",
      "../01_simulation/Marya246_Lavette209_Ernser583_7c7f6957-c56e-cf89-4b5f-131fe008ae55.json\n",
      "No allergies found!\n",
      "../01_simulation/Forrest301_Franecki195_cb797f3c-5552-3968-3345-ba88ac9b9e5b.json\n",
      "No allergies found!\n",
      "../01_simulation/Novella551_Heller342_0f3c506e-7221-8dc0-1fba-c307784c586c.json\n",
      "No allergies found!\n",
      "../01_simulation/Beulah33_Feil794_7bd01283-5e27-f4dc-52f4-744de2512418.json\n",
      "Allergies found!\n",
      "../01_simulation/Wilton999_Rath779_6824c567-a5b2-8741-2dc4-b13ec092dd27.json\n",
      "Allergies found!\n",
      "../01_simulation/Maryellen651_Monica757_Bauch723_76797576-3f7f-a4f3-86a6-a309d0a27d07.json\n",
      "No allergies found!\n",
      "../01_simulation/Cassaundra447_Kathline630_Jones311_b68d8826-64bb-47b1-aa53-59357ef92b60.json\n",
      "No allergies found!\n",
      "../01_simulation/Broderick767_Ratke343_41321921-4aa9-395b-c813-f5d1d4e2810a.json\n",
      "No allergies found!\n",
      "../01_simulation/Maryetta775_Lee268_Huels583_76913a1b-9235-032b-e8af-48b99e533fd6.json\n",
      "No allergies found!\n",
      "../01_simulation/Tamar361_Myrle831_Kerluke267_4cf45a0b-d8fa-de19-0865-de5fdb419a66.json\n",
      "No allergies found!\n",
      "../01_simulation/Chang901_Zemlak964_fa7b77ea-3132-64f8-8b9c-bb150882d30e.json\n",
      "No allergies found!\n",
      "../01_simulation/Ronny764_Marks830_6770cac0-ddbc-845e-854c-5805f725fbfb.json\n",
      "No allergies found!\n",
      "../01_simulation/Noble66_Powlowski563_e02ae963-bbd6-cd3e-81a2-37e93a0c04aa.json\n",
      "No allergies found!\n",
      "../01_simulation/Trang668_Will178_331a724a-b66a-f75b-e257-b4753f0e3444.json\n",
      "No allergies found!\n",
      "../01_simulation/Emmett200_Friesen796_6e98618b-3ffa-b6d7-2e70-423e87800b15.json\n",
      "No allergies found!\n",
      "../01_simulation/Gertie348_Shaquana156_Friesen796_0005eff6-83bd-a7d5-235b-0a6c2b4b77e0.json\n",
      "No allergies found!\n",
      "../01_simulation/Steven797_Leannon79_565500a1-9af9-0f59-c37f-a1d0f6e7ca72.json\n",
      "No allergies found!\n",
      "../01_simulation/Warner493_Barrows492_2bdd7e74-4cfe-2ed9-957e-65a8b024996d.json\n",
      "No allergies found!\n",
      "../01_simulation/Cristobal567_Grimes165_747a005b-228d-e2fe-0e33-551f3d49a4c3.json\n",
      "No allergies found!\n",
      "../01_simulation/Danika134_Bogan287_e9e782e3-562b-e16f-a356-ee7815e295f0.json\n",
      "No allergies found!\n",
      "../01_simulation/Gil594_West559_309675ae-8b55-7980-308f-51900f538f70.json\n",
      "No allergies found!\n",
      "../01_simulation/Don899_Kilback373_34217d52-e14a-b76e-3b6f-d790c19b3de2.json\n",
      "No allergies found!\n",
      "../01_simulation/Adan632_Collier206_97d1503a-9cc9-dcfe-ed3f-e1a5561070b3.json\n",
      "Allergies found!\n",
      "../01_simulation/Edwardo860_Barton704_b9c5b161-0a6c-8fbe-9c17-5167260e6ad0.json\n",
      "No allergies found!\n",
      "../01_simulation/Luis923_Greenholt190_3b188a93-ed7e-a9f0-daf9-05537f440707.json\n",
      "No allergies found!\n",
      "../01_simulation/Jacquelyne425_Joshua658_Ledner144_74b257f3-95d9-eeab-1d10-d1c422c0dfa3.json\n",
      "No allergies found!\n",
      "../01_simulation/Lucas404_West559_12e4a2ba-5bd8-6da1-da76-05c96875d007.json\n",
      "No allergies found!\n",
      "../01_simulation/Noreen211_Celena734_Adams676_7a11c36b-390c-ab86-50ee-e940ab67fd65.json\n",
      "No allergies found!\n",
      "../01_simulation/Elsy53_Hilaria948_Gislason620_94aefbe2-53f4-e5fa-8398-098adc70fd11.json\n",
      "No allergies found!\n",
      "../01_simulation/Dwight645_Sipes176_b7e6c16d-2ad8-40c1-f7aa-0e0fee35f717.json\n",
      "No allergies found!\n",
      "../01_simulation/Zaida719_Roberts511_9f095bc0-1bbd-1d4f-1169-420e2a812aea.json\n",
      "Allergies found!\n",
      "../01_simulation/Shon148_Kilback373_ef5ef540-2f1e-b55c-a3a2-6dc890a38530.json\n",
      "No allergies found!\n",
      "../01_simulation/Delena885_Myra819_Quigley282_aa207609-0af0-e319-f6b9-3bf426ffba47.json\n",
      "No allergies found!\n",
      "../01_simulation/Harris789_Conroy74_55657cae-6860-cdcc-2196-feae85ee57e3.json\n",
      "No allergies found!\n",
      "../01_simulation/Horace32_Haley279_f0bc3216-d49f-d8e2-0aff-6dbbee425a5a.json\n",
      "No allergies found!\n",
      "../01_simulation/Lonnie913_Ziemann98_913f3656-3606-12f0-e21e-e8d4d7b1b63b.json\n",
      "No allergies found!\n",
      "../01_simulation/Shandra823_Whitley172_Cassin499_270cba3f-a152-d243-d617-eb12996eb3d4.json\n",
      "No allergies found!\n",
      "../01_simulation/Nicholas495_Howell947_221669dc-2317-1ab2-086e-f3cfefb17ce1.json\n",
      "No allergies found!\n",
      "../01_simulation/Cristina921_Roybal79_c3bb1e5a-f370-1527-c618-4636d43dd6f3.json\n",
      "No allergies found!\n",
      "../01_simulation/Elba502_Ariane992_Crona259_28c54222-8901-b307-329a-ddc59273d9f8.json\n",
      "No allergies found!\n",
      "../01_simulation/Sondra191_Brekke496_e6d76550-1b0d-6989-3e67-7b380d27f1d2.json\n",
      "No allergies found!\n",
      "../01_simulation/Nikki942_Tereasa291_Schoen8_cf156cda-e520-8d7a-0bef-abbd7c0930bf.json\n",
      "No allergies found!\n",
      "../01_simulation/Raven88_Constance642_Barton704_29014f9d-c685-0d90-5b91-02a332351394.json\n",
      "No allergies found!\n",
      "../01_simulation/Drew592_Stracke611_4be5bd06-7e46-e25d-dba6-81c351c8c328.json\n",
      "No allergies found!\n",
      "../01_simulation/Douglas31_Conn188_7ce4288c-aae4-9a86-0a65-7efc70c245e1.json\n",
      "No allergies found!\n",
      "../01_simulation/Beatriz277_Nieto461_c240ba7d-d4cd-fdc1-781b-51e8cbe86783.json\n",
      "No allergies found!\n",
      "../01_simulation/Waylon572_Moen819_4d983839-42ed-672f-d173-f8f69c608736.json\n",
      "No allergies found!\n",
      "../01_simulation/Raymond398_Grimes165_d5a8f729-d7ea-aac1-5cd8-afac23ae73ae.json\n",
      "No allergies found!\n",
      "../01_simulation/Grover559_Kreiger457_3d5157c8-3755-0901-88ec-a574a9ab300e.json\n",
      "No allergies found!\n",
      "../01_simulation/Mistie167_Carroll471_12e3adfd-0a91-911a-69fc-2f5755b6359d.json\n",
      "No allergies found!\n",
      "../01_simulation/Doris153_Tawanna466_Kuvalis369_67e68f6b-42df-18aa-7bf9-bc967de08175.json\n",
      "No allergies found!\n",
      "../01_simulation/Jeff859_Schmeler639_4c779703-69a1-2f6e-92ff-7d0d8286bef9.json\n",
      "No allergies found!\n",
      "../01_simulation/Buster609_Sipes176_c164342b-0b1e-28c4-6c34-f1a0f563e94b.json\n",
      "Allergies found!\n",
      "../01_simulation/Boris111_Littel644_8b1bb701-05fc-b625-4b17-5c8865caff23.json\n",
      "No allergies found!\n",
      "../01_simulation/Sheldon401_Zieme486_80eeaf0e-50a6-263f-5b6e-d80c6a890033.json\n",
      "No allergies found!\n",
      "../01_simulation/Kristofer887_Becker968_0d44a175-18c4-a804-f697-d956c484d37a.json\n",
      "No allergies found!\n",
      "../01_simulation/Guillermo498_Cornejo190_753bf038-0bd7-ffb3-83dc-991a93562f36.json\n",
      "Allergies found!\n",
      "../01_simulation/Marilu588_Fonseca493_9835053b-4c86-3959-1405-ecf72202f2eb.json\n",
      "No allergies found!\n",
      "../01_simulation/Ismael683_Bailey598_231e9eff-b1b9-517f-9a9e-6040d8057971.json\n",
      "No allergies found!\n",
      "../01_simulation/Dick869_Schamberger479_a6cb97cd-41a7-3510-0c5c-7eb5c3fff6a6.json\n",
      "No allergies found!\n",
      "../01_simulation/Sasha806_Bernhard322_222b1f2f-5394-8a3b-02e9-971155612fe3.json\n",
      "No allergies found!\n",
      "../01_simulation/Damon455_Nitzsche158_17f24956-1da3-a333-2c8f-0673690014eb.json\n",
      "No allergies found!\n",
      "../01_simulation/Delcie812_Lera808_Beer512_9501bb98-c2c7-e538-9177-d39f04948c31.json\n",
      "Allergies found!\n",
      "../01_simulation/Josef103_Murphy561_0c9f6570-195c-9c53-5f9b-d1ad67f56164.json\n",
      "No allergies found!\n",
      "../01_simulation/Saundra460_Gislason620_7b4df1c6-2cfa-9ca4-9aeb-604a0d76d203.json\n",
      "No allergies found!\n",
      "../01_simulation/Otto672_Wolff180_5a8a1ec8-cd59-fc6c-601e-d3679ac9071f.json\n",
      "No allergies found!\n",
      "../01_simulation/Kit446_Terina405_Rowe323_9d1e3b97-8013-5f60-d66a-e57dab7d6495.json\n",
      "No allergies found!\n",
      "../01_simulation/Carson894_Hilll811_e989847a-2a66-cd4f-e0ac-c36b7d7cf872.json\n",
      "No allergies found!\n",
      "../01_simulation/Randy380_Larson43_07576856-c502-8aec-b191-a32db6d6a265.json\n",
      "No allergies found!\n",
      "../01_simulation/Adele475_Christie481_Weissnat378_1ba3e03e-2ab9-78a4-df20-9cf48b39c89f.json\n",
      "No allergies found!\n",
      "../01_simulation/Melvin857_Karon907_Kuhn96_c1efd73e-8f45-6fc1-13d4-0e2412478acb.json\n",
      "No allergies found!\n",
      "../01_simulation/Jana258_Schmitt836_f54d3859-8e19-33a9-40a3-76c5be3bcaea.json\n",
      "No allergies found!\n",
      "../01_simulation/Amal279_Lidia103_Leffler128_5f950cfa-a276-2324-10e1-08111953a7bd.json\n",
      "No allergies found!\n",
      "../01_simulation/Ian270_Kling921_df8fa567-61da-3ae7-db4a-9250884d453e.json\n",
      "No allergies found!\n",
      "../01_simulation/Marcelle381_Florida645_Waelchi213_27e3d8c4-a257-2bce-6c37-432dd2ab7d2b.json\n",
      "No allergies found!\n",
      "../01_simulation/Robby860_Stokes453_41e6e3a6-c98e-3b21-913f-70e88d9ef58a.json\n",
      "No allergies found!\n",
      "../01_simulation/Emilio417_Macejkovic424_e16c3d9e-adb3-64e7-f390-b4b554555e0c.json\n",
      "Allergies found!\n",
      "../01_simulation/German382_Davis923_6dd0226a-e70f-d874-6349-f3e710ea5821.json\n",
      "No allergies found!\n",
      "../01_simulation/Stephen891_Mari763_Price929_9fdefa02-75e9-debe-d859-9cf968cdd9f0.json\n",
      "No allergies found!\n",
      "../01_simulation/Hassie51_Mignon230_Koelpin146_58d1cdfd-f58b-5270-0708-bd06e7138729.json\n",
      "No allergies found!\n",
      "../01_simulation/Gerard367_Altenwerth646_3db22d79-9226-e153-de36-5417bf98c115.json\n",
      "No allergies found!\n",
      "../01_simulation/Julio255_Hurtado459_75bcfef0-6c1a-0912-4d07-4985cc8b5b25.json\n",
      "Allergies found!\n",
      "../01_simulation/Val761_Boyer713_92f5faad-f4fb-33a1-b22c-4412f1ee223f.json\n",
      "Allergies found!\n",
      "../01_simulation/Maddie576_Smitham825_08b3afc0-dd46-aed2-b463-01ed20bc8f91.json\n",
      "No allergies found!\n",
      "../01_simulation/Gerald181_Dietrich576_179b9671-55c5-1a17-b112-585113af6226.json\n",
      "No allergies found!\n",
      "../01_simulation/Guadalupe206_Hackett68_690004d5-1f4f-a3c8-6e5a-1c9417580b3a.json\n",
      "No allergies found!\n",
      "../01_simulation/Tori754_Dottie687_Harris789_9503d88c-5091-a6ab-5ba5-2cf63432e5a4.json\n",
      "No allergies found!\n",
      "../01_simulation/Normand813_Leffler128_992c6f88-cd3a-f6ae-6844-3d6dc1eda452.json\n",
      "No allergies found!\n",
      "../01_simulation/Elaina826_Juliana372_McLaughlin530_3ca0117e-a77b-dbf4-f53f-be2ca8cef2b5.json\n",
      "Allergies found!\n",
      "../01_simulation/Shaunna800_Schowalter414_9eef1cc0-c67b-a207-90ab-d48b0f1fe859.json\n",
      "No allergies found!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "json_files = glob.glob('../01_simulation/*json')\n",
    "\n",
    "# We define global empty lists of allergies types and susbtances\n",
    "\n",
    "# We create a list of allergy types to not create redundant nodes\n",
    "allergy_types_all = []\n",
    "\n",
    "# And we do the same for allergy substances\n",
    "allergy_substances = []\n",
    "\n",
    "# We repeat the code from above to recontruct our ontology from scratch\n",
    "\n",
    "# Importing ontology\n",
    "g = Graph()\n",
    "g.parse(\"sphn_ontology.ttl\")\n",
    "\n",
    "# Adding allergies and patients as prefixes\n",
    "allergies = Namespace(\"http://sib.swiss/allergies/\")\n",
    "g.bind(\"allergies\", allergies)\n",
    "patients = Namespace(\"http://sib.swiss/fictivePatients/\")\n",
    "g.bind(\"patients\", patients)\n",
    "substances = Namespace(\"http://sib.swiss/substances/\")\n",
    "g.bind(\"substances\", substances)\n",
    "\n",
    "# Adding also SPHN as a variable since this is not automatic\n",
    "sphn = Namespace(\"https://biomedit.ch/rdf/sphn-ontology/sphn#\")\n",
    "\n",
    "# We create a splitting function to extract the terms we need\n",
    "# from the allergy types we find\n",
    "\n",
    "def split_allergen(allergen):\n",
    "    first_split = Literal(allergen).split(' (')[0]\n",
    "    no_spaces = first_split.replace(' ', '')\n",
    "    # remove special characters\n",
    "    clean = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", no_spaces)\n",
    "    return(clean)\n",
    "\n",
    "def split_allergies_types(allergies):\n",
    "    first_split = Literal(allergies).split('[')[1]\n",
    "    second_split = first_split.split(']')[0]\n",
    "    # remove special characters\n",
    "    clean = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", second_split)\n",
    "    return(clean)\n",
    "\n",
    "# looping through JSON files\n",
    "for json_file in json_files:\n",
    "    \n",
    "    print(json_file)\n",
    "    \n",
    "    # Load data\n",
    "    data = json.load(open(json_file, 'r'))\n",
    "    \n",
    "    # Adding patient ID to the ontology\n",
    "    ID_patient = Literal(data['entry'][0]['resource']['id'])\n",
    "    g.add((URIRef(patients + ID_patient), RDF.type, sphn.SubjectPseudoIdentifier))\n",
    "\n",
    "    # we convert JSON import into dataframe\n",
    "    df = pd.DataFrame.from_dict(pd.json_normalize(data['entry']), orient='columns')\n",
    "\n",
    "    # We isolate the rows with allergies and get the allergy name(s)\n",
    "\n",
    "    allergen_rows = df[df['resource.resourceType'] == 'AllergyIntolerance']\n",
    "    \n",
    "    if len(allergen_rows) == 0:\n",
    "        print(\"No allergies found!\")\n",
    "        continue\n",
    "    else:\n",
    "        print(\"Allergies found!\")\n",
    "        allergen = allergen_rows['resource.code.text']\n",
    "\n",
    "        # We isolate the allergy type as well\n",
    "\n",
    "        allergies_types = allergen_rows['resource.category']\n",
    "    \n",
    "        # Now we create a loop to go through the terms\n",
    "        # and add them to our ontology\n",
    "\n",
    "        for i,j in zip(allergen,allergies_types):\n",
    "        \n",
    "            # Convert allergy type and substance to literal\n",
    "            allergy_type = Literal(split_allergies_types(j))\n",
    "            allergy_substance = Literal(split_allergen(i))\n",
    "    \n",
    "            # Check if any is part of a global list\n",
    "            # and if not, we can add them to the ontology\n",
    "    \n",
    "            if allergy_type not in allergy_types_all:\n",
    "                allergy_types_all.append(allergy_type)\n",
    "                g.add((URIRef(allergies + allergy_type), RDF.type, sphn.Allergy))\n",
    "        \n",
    "            if allergy_substance not in allergy_substances:\n",
    "                allergy_substances.append(allergy_substance)\n",
    "                g.add((URIRef(allergies + allergy_type), sphn.hasSubstance, URIRef(substances + allergy_substance)))\n",
    "    \n",
    "            # Add to ontology by associating to the patient ID\n",
    "            g.add((URIRef(allergies + allergy_type), sphn.hasSubjectPseudoIdentifier, URIRef(patients + ID_patient)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f21afac-3aee-4dcf-adab-7893738e5b01",
   "metadata": {},
   "source": [
    "We can check if the ontology is longer and if we filled all of our allergies substances and types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e5dad124-f754-4e61-af90-ee8e9f2907ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8877"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g)\n",
    "#print(g.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ce933c46-afe2-470c-8415-bb3acaaef34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rdflib.term.Literal('Lisinopril'), rdflib.term.Literal('Ibuprofen'), rdflib.term.Literal('Latex'), rdflib.term.Literal('Mold'), rdflib.term.Literal('Housedustmite'), rdflib.term.Literal('Animaldander'), rdflib.term.Literal('Grasspollen'), rdflib.term.Literal('Treepollen'), rdflib.term.Literal('Cowsmilk'), rdflib.term.Literal('Eggs'), rdflib.term.Literal('Shellfish'), rdflib.term.Literal('Fish'), rdflib.term.Literal('Beevenom'), rdflib.term.Literal('PenicillinV'), rdflib.term.Literal('Treenut'), rdflib.term.Literal('Aspirin'), rdflib.term.Literal('Peanut'), rdflib.term.Literal('SulfamethoxazoleTrimethoprim')]\n",
      "[rdflib.term.Literal('medication'), rdflib.term.Literal('environment'), rdflib.term.Literal('food')]\n"
     ]
    }
   ],
   "source": [
    "print(allergy_substances)\n",
    "print(allergy_types_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576eb504-54ca-485f-a523-537bc5fea37c",
   "metadata": {},
   "source": [
    "As a final step we save our extended ontology to a Turtle file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e3d2b1ae-303c-4a46-95d5-02efafdb3b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N3fc40be2504f4a0eae9020764eac5774 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize(destination=\"sphn_ontology_extended.ttl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
